{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import librosa\n",
    "import pywt\n",
    "from skimage.restoration import denoise_wavelet\n",
    "\n",
    "from loess.loess_1d import loess_1d\n",
    "import statsmodels.api as sm\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from tqdm import tqdm\n",
    "\n",
    "import argparse\n",
    "from os import listdir\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_audio_filenames(directory: str) -> list:\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    return [ filename for filename in listdir(directory) if filename.endswith('.wav') ]\n",
    "\n",
    "\n",
    "def read_audio_content(filepath: str, sample_rate=4000):\n",
    "    '''\n",
    "    '''\n",
    "    data, sr = librosa.load(filepath, sr=sample_rate)\n",
    "    return data, sr\n",
    "\n",
    "\n",
    "def segment_audio_content(audio, sample_rate=4000, segment_length=5):\n",
    "    ''''''\n",
    "    segments = []\n",
    "    audio_length = len(audio) / sample_rate\n",
    "\n",
    "    # print('Audio length', audio_length)\n",
    "\n",
    "    segment_index = 0\n",
    "    while segment_index < audio_length:\n",
    "        t_start = segment_index * sample_rate\n",
    "        t_end = t_start + segment_length * sample_rate\n",
    "\n",
    "        segment = audio[ t_start : t_end ]\n",
    "        segments.append(np.pad(segment, (0, sample_rate * segment_length - len(segment)), 'constant'))\n",
    "        segment_index += segment_length\n",
    "\n",
    "    # print(segment_index / segment_length, 'segments read')\n",
    "    # print([ len(s) for s in segments ])\n",
    "    return segments\n",
    "\n",
    "\n",
    "def preprocess(audio):\n",
    "    ''''''\n",
    "    processed = wavelet_denoise(audio)\n",
    "    processed = apply_loess(processed)\n",
    "    processed = zscore_normalize(processed)\n",
    "    return processed\n",
    "\n",
    "\n",
    "def wavelet_denoise(audio):\n",
    "    '''Wavelet denoise\n",
    "    '''\n",
    "    return denoise_wavelet(audio, wavelet='db5', method='BayesShrink', mode='soft', wavelet_levels=4)\n",
    "    # return pywt.wavedec(audio, 'db5', mode='zero', level=4)[0]\n",
    "\n",
    "\n",
    "def apply_loess(audio, frac=0.1):\n",
    "    '''\n",
    "    '''\n",
    "    lowess = sm.nonparametric.lowess\n",
    "    l = lowess(audio, np.arange(0, len(audio), 1), frac=frac)[:, 1]\n",
    "    return audio - l\n",
    "    \n",
    "\n",
    "def zscore_normalize(audio):\n",
    "    '''\n",
    "    '''\n",
    "    return scipy.stats.zscore(audio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS_OF_INTEREST = ['Healthy', 'Asthma', 'Pneumonia', 'Bron', 'COPD', 'Heart failure']\n",
    "\n",
    "SEGMENTS_LENGTH = 5\n",
    "\n",
    "JOIN_DATASETS = True\n",
    "\n",
    "ICBHI_SAVE_PATH = 'arr_icbhi.npy'\n",
    "KING_ABDULLAH_SAVE_PATH = 'arr_king_abdullah.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 336/336 [1:19:59<00:00, 14.28s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Diagnosis\n",
       "Asthma           366\n",
       "Bron              27\n",
       "COPD             111\n",
       "Healthy          418\n",
       "Heart failure    183\n",
       "Pneumonia         63\n",
       "Name: Diagnosis, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KING_ABDULLAH_DATASET_BASEDIR = join('Audio_Files')\n",
    "\n",
    "king_abdullah_audio_filenames = read_audio_filenames(KING_ABDULLAH_DATASET_BASEDIR)\n",
    "\n",
    "\n",
    "labels_map = {\n",
    "    'N': 'Healthy',\n",
    "    'Copd': 'COPD',\n",
    "}\n",
    "\n",
    "audios = []\n",
    "for filename in tqdm(king_abdullah_audio_filenames):\n",
    "\n",
    "    (id, diagnosis) = filename.split(',')[0].split('_')\n",
    "    diagnosis = diagnosis.capitalize()\n",
    "    audio, sample_rate = read_audio_content(join(KING_ABDULLAH_DATASET_BASEDIR, filename))\n",
    "    segments = segment_audio_content(audio, sample_rate, SEGMENTS_LENGTH)\n",
    "\n",
    "    for (seg_no, segment) in enumerate(segments):\n",
    "\n",
    "        label = labels_map.get(diagnosis, diagnosis)\n",
    "\n",
    "        processed_segment = preprocess(segment)\n",
    "\n",
    "        row = {'ID': id, 'segment_no': seg_no, 'audio_data': processed_segment, 'Diagnosis': label}\n",
    "        audios.append(row)\n",
    "\n",
    "df_audio_diagnosis_ka = pd.DataFrame(audios)\n",
    "df_audio_diagnosis_ka = df_audio_diagnosis_ka[df_audio_diagnosis_ka.Diagnosis.isin(LABELS_OF_INTEREST)]\n",
    "df_audio_diagnosis_ka.groupby('Diagnosis')['Diagnosis'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.save(KING_ABDULLAH_SAVE_PATH, df_audio_diagnosis_ka.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 920/920 [3:57:22<00:00, 15.48s/it]  \n"
     ]
    }
   ],
   "source": [
    "ICBHI_DATASET_BASEDIR = 'Respiratory_Sound_Database'\n",
    "ICBHI_AUDIO_TXT_DIR = join(ICBHI_DATASET_BASEDIR, 'audio_and_txt_files')\n",
    "\n",
    "\n",
    "def create_icbhi2017_audio_dataframe(basedir: str, patient_diagnosis: dict) -> pd.DataFrame:\n",
    "    '''\n",
    "    '''\n",
    "    rows = []\n",
    "\n",
    "    filenames = read_audio_filenames(basedir)\n",
    "\n",
    "    for filename in tqdm(filenames):\n",
    "\n",
    "        parts = filename.split('.')[0].split('_')\n",
    "        id = int(parts[0])\n",
    "\n",
    "        if id not in patient_diagnosis:\n",
    "            continue\n",
    "\n",
    "\n",
    "        diagnosis = patient_diagnosis[id]\n",
    "        audio_content, sample_rate = read_audio_content(join(basedir, filename))\n",
    "        segments = segment_audio_content(audio_content)\n",
    "\n",
    "        for (segment_no, segment) in enumerate(segments):\n",
    "            \n",
    "            # Because wavelet denoise throws an ValueError when the array is only zeroes.\n",
    "            # Also, a segment with only zeroes might be the end of the audio filled with zeroes.\n",
    "            if np.all(segment == 0):\n",
    "                continue\n",
    "\n",
    "            processed_segment = preprocess(segment)\n",
    "\n",
    "            row = { 'ID': str(id), 'segment_no': segment_no, 'audio_data': processed_segment, \n",
    "                'Diagnosis': diagnosis }\n",
    "            rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_diagnosis_icbhi = pd.read_table('ICBHI_Challenge_diagnosis.txt', header=None, names=['ID', 'Diagnosis'])\n",
    "\n",
    "filter_bron_icbhi = df_diagnosis_icbhi['Diagnosis'].isin(['Bronchiectasis', 'Bronchiolitis'])\n",
    "df_diagnosis_icbhi.loc[filter_bron_icbhi, 'Diagnosis'] = 'Bron'\n",
    "\n",
    "filter_diagnosis_icbhi = df_diagnosis_icbhi['Diagnosis'].isin(LABELS_OF_INTEREST)\n",
    "df_diagnosis_icbhi = df_diagnosis_icbhi[filter_diagnosis_icbhi]\n",
    "\n",
    "patient_diagnosis_icbhi_dict = df_diagnosis_icbhi.set_index('ID').to_dict()['Diagnosis']\n",
    "\n",
    "df_audio_diagnosis_icbhi = create_icbhi2017_audio_dataframe(ICBHI_AUDIO_TXT_DIR, patient_diagnosis_icbhi_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(ICBHI_SAVE_PATH, df_audio_diagnosis_icbhi.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if JOIN_DATASETS == True:\n",
    "\n",
    "    cols = ['ID', 'segment_no', 'audio_data', 'Diagnosis']\n",
    "\n",
    "    try:\n",
    "        df_audio_diagnosis_ka\n",
    "    except NameError:\n",
    "        df_audio_diagnosis_ka = pd.DataFrame(\n",
    "            np.load(KING_ABDULLAH_SAVE_PATH, allow_pickle=True), columns=cols\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        df_audio_diagnosis_icbhi\n",
    "    except NameError:\n",
    "        df_audio_diagnosis_icbhi = pd.DataFrame(\n",
    "            np.load(ICBHI_SAVE_PATH, allow_pickle=True), columns=cols\n",
    "        )\n",
    "\n",
    "    df_audio_diagnosis_all = pd.concat([\n",
    "        df_audio_diagnosis_ka,\n",
    "        df_audio_diagnosis_icbhi,\n",
    "    ])\n",
    "\n",
    "    DF_ALL_SAVE_PATH = 'arr_audio_all.npy'\n",
    "    np.save(DF_ALL_SAVE_PATH, df_audio_diagnosis_all.to_numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3744d86ee6155b73f75be8bdca02e68fd50f74efe5d040ce37fca7cac236386b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
